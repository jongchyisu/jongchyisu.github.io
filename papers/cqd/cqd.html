<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<!-- saved from url=(0050)http://people.cs.umass.edu/~kalo/papers/shapepfcn/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Adapting Models to Signal Degradation using Distillation</title>

<link media="all" href="../style.css" type="text/css" rel="stylesheet">
<style type="text/css" media="all">
img {
	PADDING-RIGHT: 0px;
	PADDING-LEFT: 10px;
	FLOAT: right;
	PADDING-BOTTOM: 10px;
	PADDING-TOP: 10px
}
#content {
	MARGIN-LEFT: auto;
 WIDTH: expression(document.body.clientWidth > 925? "925px": "auto" );
	MARGIN-RIGHT: auto;
	TEXT-ALIGN: left;
	max-width: 925px
}
body {
	TEXT-ALIGN: center
}
</style>
</head>
<body>
<div id="content">
  <h1 align="center">Adapting Models to Signal Degradation using Distillation</h1>
  <img alt="teaser" src="teaser.png" width="300">
  <br>
  <br>
  <br>
  <h2>People</h2>
  <ul id="people">
    <li><a href="http://people.cs.umass.edu/~jcsu/">Jong-Chyi Su</a> </li>
    <li><a href="http://people.cs.umass.edu/~smaji/">Subhransu Maji</a> </li>
  </ul>
  <br>
  <br>
  <h2>Abstract</h2>
  <p align="justify">Model compression and knowledge distillation have been successfully applied for cross-architecture and cross-domain transfer learning. However, a key requirement is that training examples are in correspondence across the domains. We show that in many scenarios of practical importance such aligned data can be synthetically generated using computer graphics pipelines allowing domain adaptation through distillation. We apply this technique to learn models for recognizing low-resolution images using labeled high-resolution images, non-localized objects using labeled localized objects, line-drawings using labeled color images, etc. Experiments on various fine-grained recognition datasets demonstrate that the technique improves recognition performance on the low-quality data and beats strong baselines for domain adaptation. Finally, we present insights into workings of the technique through visualizations and relating it to existing literature. </p>
  
  <h2>Paper</h2>
  <a href="http://arxiv.org/abs/1604.00433">arXiv</a>
  <br>
  <a href="http://people.cs.umass.edu/~jcsu/papers/cqd/cqd.pdf">pdf</a>
  <br>
  <a href="http://people.cs.umass.edu/~jcsu/papers/cqd/cqd.bib">Bibtex</a><br>
  
  <h2>Poster</h2>
  <a href="http://people.cs.umass.edu/~jcsu/papers/cqd/poster.pdf">poster</a><br>  

  <h2> Source Code</h2>
  <p>Coming soon on gitthub!</p>

  <h2>Citation</h2>
  <p>Jong-Chyi Su, Subhransu Maji, "Adapting Models to Signal Degradation using Distillation", <em> British Machine Vision Conference (BMVC), 2017</em> <br>

  <div id="footer"><a href="http://people.cs.umass.edu/~jcsu/">back to Jong-Chyi's page</a></div>
</div>


</body></html>
